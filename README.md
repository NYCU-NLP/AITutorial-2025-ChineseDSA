## 資料夾說明

### Regional-CNN-LSTM (Wang et al., 2016)
- regional-cnn-lstm.ipynb: 程式碼
- CVAT_all.csv: 訓練資料
- DSAMST-ValidationSet_ans.csv: 測試資料
- word2vec: 詞嵌入向量資料夾

### BERT (Devlin et al., 2019)
- bert.ipynb: 程式碼
- SIGHAN2024_dimABSA_TrainingSet1_Traditional.json: 訓練資料
- SIGHAN2024_dimABSA_Testing_Task1_Traditional.json: 測試資料

## Reference
Jin Wang, Liang-Chih Yu, K. Robert Lai, and Xuejie Zhang. 2016. Dimensional Sentiment Analysis Using a Regional CNN-LSTM Model. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)*, pages 225–230, Berlin, Germany. Association for Computational Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In *Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.
